apiVersion: influxdata.com/v2alpha1
kind: Variable
metadata:
    name: kind_wilson_426003
spec:
    language: flux
    name: bucket
    query: |-
        buckets()
          |> filter(fn: (r) => r.name !~ /^_/)
          |> rename(columns: {name: "_value"})
          |> keep(columns: ["_value"])
    type: query
---
apiVersion: influxdata.com/v2alpha1
kind: Dashboard
metadata:
    name: interesting_hugle_426001
spec:
    charts:
      - height: 1
        kind: Markdown
        name: Name this Cell
        note: This dashboard gives you an overview of [Docker](https://docker.com)
            metrics. See the [Telegraf Documentation](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker)
            for help configuring these plugins.
        queries: null
        width: 12
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        height: 1
        kind: Single_Stat
        name: System Uptime
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "system")
                  |> filter(fn: (r) => r._field == "uptime")
                  |> window(period: 1h)
                  |> last()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> map(fn: (r) => ({r with _value: float(v: r._value) / 86400.0}))
                  |> yield(name: "last")
        suffix: ' days'
        width: 3
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
            suffix: '%'
          - base: "10"
            name: y2
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: Disk Usage
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "disk")
                  |> filter(fn: (r) => r._field == "used_percent")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 3
        yPos: 2
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: 'Number of Docker containers '
        queries:
          - query: |-
                from(bucket:v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "docker")
                  |> filter(fn: (r) => r._field == "n_containers" or r._field == "n_containers_paused" or r._field == "n_containers_running" or r._field == "n_containers_stopped")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 3
        yPos: 5
      - axes:
          - base: "10"
            name: y2
            scale: linear
          - base: "10"
            name: x
            scale: linear
          - base: "2"
            label: Bytes
            name: y
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: Network TX trafic per container / sec
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop:v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "docker_container_net")
                  |> filter(fn: (r) => r._field == "tx_bytes")  
                  |> derivative(unit:1s, nonNegative: false)
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
                  |> group(columns: ["_value", "_time", "_start", "_stop"],mode: "except")
        width: 6
        xCol: _stop
        yCol: _value
        yPos: 8
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 2
        height: 1
        kind: Single_Stat
        name: nCPUs
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "system")
                  |> filter(fn: (r) => r._field == "n_cpus")
                  |> window(period: v.windowPeriod)
                  |> last()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "last")
        suffix: ' cpus'
        width: 2
        xPos: 3
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
            suffix: '%'
          - base: "10"
            name: y2
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: CPU Usage
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "cpu")
                  |> filter(fn: (r) => r._field == "usage_user" or r._field == "usage_system" or r._field == "usage_idle")
                  |> filter(fn: (r) => r.cpu == "cpu-total")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 3
        xPos: 3
        yPos: 2
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: CPU usage per container
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "cpu" or r._measurement == "docker_container_cpu")
                  |> filter(fn: (r) => r._field == "usage_percent")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
                  |> yield(name: "mean")
        width: 3
        xPos: 3
        yPos: 5
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 2
        height: 1
        kind: Single_Stat
        name: System Load
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "system")
                  |> filter(fn: (r) => r._field == "load1")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 2
        xPos: 5
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            label: Load
            name: y
            scale: linear
          - base: "10"
            name: y2
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: System Load
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "system")
                  |> filter(fn: (r) => r._field == "load1" or r._field == "load5" or r._field == "load15")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 3
        xPos: 6
        yPos: 2
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: Memory usage % per container
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "docker_container_mem")
                  |> filter(fn: (r) => r._field == "usage_percent")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
                  |> yield(name: "mean")
        width: 3
        xPos: 6
        yPos: 5
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "2"
            label: Bytes
            name: y
            scale: linear
          - base: "10"
            name: y2
            scale: linear
        colors:
          - hex: '#FDC44F'
            name: Cthulhu
            type: scale
          - hex: '#007C76'
            name: Cthulhu
            type: scale
          - hex: '#8983FF'
            name: Cthulhu
            type: scale
        geom: line
        height: 3
        kind: Xy
        name: Network RX trafic per container / sec
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "docker_container_net")
                  |> filter(fn: (r) => r._field == "rx_bytes" )
                  |> derivative(unit: 1s, nonNegative: false)
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
        width: 6
        xCol: _stop
        xPos: 6
        yCol: _value
        yPos: 8
      - colors:
          - hex: '#00C9FF'
            name: laser
            type: text
        decimalPlaces: 2
        height: 1
        kind: Single_Stat
        name: Total Memory
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "mem")
                  |> filter(fn: (r) => r._field == "total")
                  |> window(period: v.windowPeriod)
                  |> last()
                  |> map(fn: (r) => ({r with _value: float(v: r._value) / 1024.0 / 1024.0 / 1024.0}))
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "last")
        suffix: ' GB'
        width: 2
        xPos: 7
        yPos: 1
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
            suffix: '%'
          - base: "10"
            name: y2
            scale: linear
        colors:
          - hex: '#00C9FF'
            name: laser
            type: text
          - hex: '#8F8AF4'
            name: Do Androids Dream of Electric Sheep?
            type: scale
          - hex: '#A51414'
            name: Do Androids Dream of Electric Sheep?
            type: scale
          - hex: '#F4CF31'
            name: Do Androids Dream of Electric Sheep?
            type: scale
        decimalPlaces: 1
        height: 2
        kind: Single_Stat_Plus_Line
        name: Memory Usage
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "mem")
                  |> filter(fn: (r) => r._field == "used_percent")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        suffix: '%'
        width: 3
        xPos: 9
        yPos: 1
      - axes:
          - base: "2"
            name: y
            scale: linear
          - base: "10"
            name: y2
            scale: linear
          - base: "10"
            name: x
            scale: linear
        geom: line
        height: 2
        kind: Xy
        name: Swap
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart)
                  |> filter(fn: (r) => r._measurement == "swap")
                  |> filter(fn: (r) => r._field == "total" or r._field == "used")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> yield(name: "mean")
        width: 3
        xPos: 9
        yPos: 3
      - axes:
          - base: "10"
            name: x
            scale: linear
          - base: "10"
            name: y
            scale: linear
        geom: line
        height: 3
        kind: Xy
        name: Memory usage per container
        queries:
          - query: |-
                from(bucket: v.bucket)
                  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
                  |> filter(fn: (r) => r._measurement == "docker_container_mem")
                  |> filter(fn: (r) => r._field == "usage")
                  |> window(period: v.windowPeriod)
                  |> mean()
                  |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
                  |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
                  |> yield(name: "mean")
        width: 3
        xPos: 9
        yPos: 5
    description: A collection of useful visualizations for monitoring your system
        stats
    name: Docker
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: affectionate_swirles_c26003
spec:
    color: '#326BBA'
    name: inputs.net
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: bold_darwin_c2600b
spec:
    color: '#326BBA'
    name: inputs.kernel
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: boring_dubinsky_c26009
spec:
    color: '#326BBA'
    name: inputs.diskio
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: compassionate_lalande_c26015
spec:
    color: '#326BBA'
    name: inputs.docker
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: earnest_meninsky_c26001
spec:
    color: '#108174'
    name: outputs.influxdb_v2
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: flamboyant_dewdney_c2600d
spec:
    color: '#326BBA'
    name: inputs.mem
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: gifted_dirac_c26007
spec:
    color: '#326BBA'
    name: inputs.disk
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: modest_robinson_c26005
spec:
    color: '#326BBA'
    name: inputs.cpu
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: practical_jang_c2600f
spec:
    color: '#326BBA'
    name: inputs.processes
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: trusting_goldwasser_c26013
spec:
    color: '#326BBA'
    name: inputs.system
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: wonderful_bose_c26011
spec:
    color: '#326BBA'
    name: inputs.swap
---
apiVersion: influxdata.com/v2alpha1
kind: Telegraf
metadata:
    name: lucid_gauss_026001
spec:
    associations:
      - kind: Label
        name: earnest_meninsky_c26001
      - kind: Label
        name: affectionate_swirles_c26003
      - kind: Label
        name: modest_robinson_c26005
      - kind: Label
        name: gifted_dirac_c26007
      - kind: Label
        name: boring_dubinsky_c26009
      - kind: Label
        name: bold_darwin_c2600b
      - kind: Label
        name: flamboyant_dewdney_c2600d
      - kind: Label
        name: practical_jang_c2600f
      - kind: Label
        name: wonderful_bose_c26011
      - kind: Label
        name: trusting_goldwasser_c26013
      - kind: Label
        name: compassionate_lalande_c26015
    config: |
        # Telegraf Configuration
        #
        # Telegraf is entirely plugin driven. All metrics are gathered from the
        # declared inputs, and sent to the declared outputs.
        #
        # Plugins must be declared in here to be active.
        # To deactivate a plugin, comment out the name and any variables.
        #
        # Use 'telegraf -config telegraf.conf -test' to see what metrics a config
        # file would generate.
        #
        # Environment variables can be used anywhere in this config file, simply surround
        # them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
        # for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


        # Global tags can be specified here in key="value" format.
        [global_tags]
          # dc = "us-east-1" # will tag all metrics with dc=us-east-1
          # rack = "1a"
          ## Environment variables can be used as tags, and throughout the config file
          # user = "$USER"


        # Configuration for telegraf agent
        [agent]
          ## Default data collection interval for all inputs
          interval = "10s"
          ## Rounds collection interval to 'interval'
          ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
          round_interval = true

          ## Telegraf will send metrics to outputs in batches of at most
          ## metric_batch_size metrics.
          ## This controls the size of writes that Telegraf sends to output plugins.
          metric_batch_size = 1000

          ## Maximum number of unwritten metrics per output.  Increasing this value
          ## allows for longer periods of output downtime without dropping metrics at the
          ## cost of higher maximum memory usage.
          metric_buffer_limit = 10000

          ## Collection jitter is used to jitter the collection by a random amount.
          ## Each plugin will sleep for a random time within jitter before collecting.
          ## This can be used to avoid many plugins querying things like sysfs at the
          ## same time, which can have a measurable effect on the system.
          collection_jitter = "0s"

          ## Default flushing interval for all outputs. Maximum flush_interval will be
          ## flush_interval + flush_jitter
          flush_interval = "10s"
          ## Jitter the flush interval by a random amount. This is primarily to avoid
          ## large write spikes for users running a large number of telegraf instances.
          ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
          flush_jitter = "0s"

          ## By default or when set to "0s", precision will be set to the same
          ## timestamp order as the collection interval, with the maximum being 1s.
          ##   ie, when interval = "10s", precision will be "1s"
          ##       when interval = "250ms", precision will be "1ms"
          ## Precision will NOT be used for service inputs. It is up to each individual
          ## service input to set the timestamp at the appropriate precision.
          ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
          precision = ""

          ## Log at debug level.
          # debug = false
          ## Log only error level messages.
          # quiet = false

          ## Log target controls the destination for logs and can be one of "file",
          ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
          ## is determined by the "logfile" setting.
          # logtarget = "file"

          ## Name of the file to be logged to when using the "file" logtarget.  If set to
          ## the empty string then logs are written to stderr.
          # logfile = ""

          ## The logfile will be rotated after the time interval specified.  When set
          ## to 0 no time based rotation is performed.  Logs are rotated only when
          ## written to, if there is no log activity rotation may be delayed.
          # logfile_rotation_interval = "0d"

          ## The logfile will be rotated when it becomes larger than the specified
          ## size.  When set to 0 no size based rotation is performed.
          # logfile_rotation_max_size = "0MB"

          ## Maximum number of rotated archives to keep, any older logs are deleted.
          ## If set to -1, no archives are removed.
          # logfile_rotation_max_archives = 5

          ## Override default hostname, if empty use os.Hostname()
          hostname = ""
          ## If set to true, do no set the "host" tag in the telegraf agent.
          omit_hostname = false


        ###############################################################################
        #                            OUTPUT PLUGINS                                   #
        ###############################################################################

        # Configuration for sending metrics to InfluxDB
        [[outputs.influxdb_v2]]
          ## The URLs of the InfluxDB cluster nodes.
          ##
          ## Multiple URLs can be specified for a single cluster, only ONE of the
          ## urls will be written to each interval.
          ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
          urls = ["$INFLUX_URL"]
          ## Token for authentication.
          token = "$INFLUX_TOKEN"
          ## Organization is the name of the organization you wish to write to; must exist.
          organization = "$INFLUX_ORG" ## Destination bucket to write into.
          bucket = "docker"
          ## The value of this tag will be used to determine the bucket.  If this
          ## tag is not set the 'bucket' option is used as the default.
          # bucket_tag = ""
                  ## If true, the bucket tag will not be added to the metric.
          # exclude_bucket_tag = false
                  ## Timeout for HTTP messages.
          # timeout = "5s"
                  ## Additional HTTP headers
          # http_headers = {"X-Special-Header" = "Special-Value"}
                  ## HTTP Proxy override, if unset values the standard proxy environment
          ## variables are consulted to determine which proxy, if any, should be used.
          # http_proxy = "http://corporate.proxy:3128"
                  ## HTTP User-Agent
          # user_agent = "telegraf"
                  ## Content-Encoding for write request body, can be set to "gzip" to
          ## compress body or "identity" to apply no encoding.
          # content_encoding = "gzip"
                  ## Enable or disable uint support for writing uints influxdb 2.0.
          # influx_uint_support = false
                  ## Optional TLS Config for use on HTTP connections.
          # tls_ca = "/etc/telegraf/ca.pem"
          # tls_cert = "/etc/telegraf/cert.pem"
          # tls_key = "/etc/telegraf/key.pem"
          ## Use TLS but skip chain & host verification
          # insecure_skip_verify = false

        ###############################################################################
        #                            INPUT PLUGINS                                    #
        ###############################################################################

        # Read metrics about cpu usage
        [[inputs.cpu]]
          ## Whether to report per-cpu stats or not
          percpu = true
          ## Whether to report total system cpu stats or not
          totalcpu = true
          ## If true, collect raw CPU time metrics.
          collect_cpu_time = false
          ## If true, compute and report the sum of all non-idle CPU states.
          report_active = false


        # Read metrics about disk usage by mount point
        [[inputs.disk]]
          ## By default stats will be gathered for all mount points.
          ## Set mount_points will restrict the stats to only the specified mount points.
          # mount_points = ["/"]

          ## Ignore mount points by filesystem type.
          ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]


        # Read metrics about disk IO by device
        [[inputs.diskio]]
          ## By default, telegraf will gather stats for all devices including
          ## disk partitions.
          ## Setting devices will restrict the stats to the specified devices.
          # devices = ["sda", "sdb", "vd*"]
          ## Uncomment the following line if you need disk serial numbers.
          # skip_serial_number = false
          #
          ## On systems which support it, device metadata can be added in the form of
          ## tags.
          ## Currently only Linux is supported via udev properties. You can view
          ## available properties for a device by running:
          ## 'udevadm info -q property -n /dev/sda'
          ## Note: Most, but not all, udev properties can be accessed this way. Properties
          ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
          # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
          #
          ## Using the same metadata source as device_tags, you can also customize the
          ## name of the device via templates.
          ## The 'name_templates' parameter is a list of templates to try and apply to
          ## the device. The template may contain variables in the form of '$PROPERTY' or
          ## '${PROPERTY}'. The first template which does not contain any variables not
          ## present for the device is used as the device name tag.
          ## The typical use case is for LVM volumes, to get the VG/LV name instead of
          ## the near-meaningless DM-0 name.
          # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


        # Get kernel statistics from /proc/stat
        [[inputs.kernel]]
          # no configuration


        # Read metrics about memory usage
        [[inputs.mem]]
          # no configuration

        # Read metrics about network interface usage
        [[inputs.net]]
          ## By default, telegraf gathers stats from any up interface (excluding loopback)
          ## Setting interfaces will tell it to gather these explicit interfaces,
          ## regardless of status.
          ##
          # interfaces = ["eth0"]
          ##
          ## On linux systems telegraf also collects protocol stats.
          ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
          ##
          # ignore_protocol_stats = false
          ##

        # Get the number of processes and group them by status
        [[inputs.processes]]
          # no configuration

        # Read metrics about swap memory usage
        [[inputs.swap]]
          # no configuration

        # Read metrics about system load & uptime
        [[inputs.system]]
          ## Uncomment to remove deprecated metrics.
          # fielddrop = ["uptime_format"]

        [[inputs.docker]]
          ## Docker Endpoint
          ##   To use TCP, set endpoint = "tcp://[ip]:[port]"
          ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"
          ##   exp: unix:///var/run/docker.sock
          endpoint = "unix:///var/run/docker.sock"

          ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)
          ## Note: configure this in one of the manager nodes in a Swarm cluster.
          ## configuring in multiple Swarm managers results in duplication of metrics.
          gather_services = false

          ## Only collect metrics for these containers. Values will be appended to
          ## container_name_include.
          ## Deprecated (1.4.0), use container_name_include
          container_names = []

          ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars
          source_tag = false

          ## Containers to include and exclude. Collect all if empty. Globs accepted.
          container_name_include = []
          container_name_exclude = []

          ## Container states to include and exclude. Globs accepted.
          ## When empty only containers in the "running" state will be captured.
          ## example: container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
          ## example: container_state_exclude = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]
          # container_state_include = []
          # container_state_exclude = []

          ## Timeout for docker list, info, and stats commands
          timeout = "5s"

          ## Whether to report for each container per-device blkio (8:0, 8:1...) and
          ## network (eth0, eth1, ...) stats or not
          perdevice = true

          ## Whether to report for each container total blkio and network stats or not
          total = true

          ## docker labels to include and exclude as tags.  Globs accepted.
          ## Note that an empty array for both will include all labels as tags
          docker_label_include = []
          docker_label_exclude = []

          ## Which environment variables should we use as a tag
          tag_env = ["JAVA_HOME", "HEAP_SIZE"]

          ## Optional TLS Config
          # tls_ca = "/etc/telegraf/ca.pem"
          # tls_cert = "/etc/telegraf/cert.pem"
          # tls_key = "/etc/telegraf/key.pem"
          ## Use TLS but skip chain & host verification
          # insecure_skip_verify = false
    description: A set of plugins for monitoring your System and Docker.
    name: Docker Monitoring
---
apiVersion: influxdata.com/v2alpha1
kind: Bucket
metadata:
    name: sleepy_napier_826001
spec:
    name: docker
    retentionRules:
      - everySeconds: 604800
        type: expire