[[inputs.http]]
#covid data in csv format
urls = ["https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/us_state_vaccinations.csv"]

#Overwrite measurement name from default `http` to `covidtracking`
name_override = "vaccine-historic"

## Data format to consume.
## Each data format has its own unique set of configuration options, read
## more about them here:
##   https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
data_format = "csv"

## Indicates how many rows to treat as a header. By default, the parser assumes
## there is no header and will parse the first row as data. If set to anything more
## than 1, column names will be concatenated with the name listed in the next header row.
## If `csv_column_names` is specified, the column names in header will be overridden.
csv_header_row_count = 1

## For assigning custom names to columns
## If this is specified, all columns should have a name
## Unnamed columns will be ignored by the parser.
## If `csv_header_row_count` is set to 0, this config must be used
csv_column_names = ["date","location","total_vaccinations","total_distributed","people_vaccinated","people_fully_vaccinated_per_hundred","total_vaccinations_per_hundred","people_fully_vaccinated","people_vaccinated_per_hundred","distributed_per_hundred","daily_vaccinations_raw","daily_vaccinations","daily_vaccinations_per_million","share_doses_used"]

## Indicates the number of rows to skip before looking for header information.
csv_skip_rows = 0

## Indicates the number of columns to skip before looking for data to parse.
## These columns will be skipped in the header as well.
csv_skip_columns = 0

## The seperator between csv fields
## By default, the parser assumes a comma (",")
csv_delimiter = ","

## The character reserved for marking a row as a comment row
## Commented rows are skipped and not parsed
csv_comment = ""

## If set to true, the parser will remove leading whitespace from fields
## By default, this is false
csv_trim_space = false

## Columns listed here will be added as tags. Any other columns
## will be added as fields.
csv_tag_columns = ["location"]

## The column to extract the name of the metric from
csv_measurement_column = ""

## The column to extract time information for the metric
## `csv_timestamp_format` must be specified if this is used
csv_timestamp_column = "date"

## The format of time data extracted from `csv_timestamp_column`
## this must be specified if `csv_timestamp_column` is specified
csv_timestamp_format = "2006-01-02"

[[outputs.influxdb_v2]]
## The URLs of the InfluxDB cluster nodes.
##
## Multiple URLs can be specified for a single cluster, only ONE of the
## urls will be written to each interval.
urls = ["$INFLUX_HOST"]

## Token for authentication.
token = "$INFLUX_TOKEN"

## Organization is the name of the organization you wish to write to; must exist.
organization = "$INFLUX_ORG"

## Destination bucket to write into.
bucket = "covid"

[global_tags]
[agent]
interval = "24h"
flush_interval = "24h"
## Telegraf will send metrics to outputs in batches of at most
## metric_batch_size metrics.
## This controls the size of writes that Telegraf sends to output plugins.
metric_batch_size = 1000

## Maximum number of unwritten metrics per output.  Increasing this value
## allows for longer periods of output downtime without dropping metrics at the
## cost of higher maximum memory usage.
metric_buffer_limit = 100000